{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdcd3ff",
   "metadata": {
    "papermill": {
     "duration": 0.003684,
     "end_time": "2025-09-19T12:46:49.685403",
     "exception": false,
     "start_time": "2025-09-19T12:46:49.681719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎨 ArtExplorer: Part 1 - The Data & AI Foundation\n",
    "\n",
    "This notebook serves as the complete data engineering and AI model creation pipeline for the ArtExplorer project, a submission for the BigQuery AI Hackathon.\n",
    "\n",
    "### **1. Purpose of This Notebook**\n",
    "\n",
    "The goal of this notebook is to perform all the necessary backend setup within Google Cloud Platform. It is designed to be run **once** to prepare the data and models that the final application will use. The key processes automated here are:\n",
    "\n",
    "1.  **Data Ingestion & Enrichment**: Downloading the raw MET Museum dataset, filtering it, and enriching it with detailed metadata via the MET Collection API.\n",
    "2.  **Cloud Storage Upload**: Uploading the cleaned and enriched data to a Google Cloud Storage bucket.\n",
    "3.  **BigQuery Ingestion**: Loading the data from GCS into a structured BigQuery table.\n",
    "4.  **AI Model Creation**: Creating the BQML remote models for text embedding (`text-embedding-004`) and generative storytelling (`gemini-2.0-flash-001`).\n",
    "5.  **Feature Engineering**: Generating the final text embeddings for each artwork using `ML.GENERATE_EMBEDDING` and storing them in a new, vector-search-ready table.\n",
    "\n",
    "    **A Note on Data Enrichment Results**\n",
    "    \n",
    "    You will notice that while the initial filtering step identifies over 2,000 potential artworks, the final enriched dataset contains a smaller number (e.g., 81 artworks in a test run with LIMIT_ROWS=100).This is an expected and intentional outcome of our robust data enrichment process. The enrich_artwork_data function calls the live MET Collection API for each artwork. Some of these API calls may fail due to various real-world factors, such as missing data for a specific Object ID on the API server or transient network issues. Our pipeline is designed to be resilient: instead of failing the entire process, it gracefully skips any artwork for which enrichment fails, ensuring that only complete, high-quality data is included in the final dataset. This demonstrates a practical approach to handling real-world, imperfect data sources.\n",
    "\n",
    "### **2. End-to-End Technical Architecture**\n",
    "\n",
    "This notebook builds the foundational components (the data pipeline) of our technical architecture. The full architecture, including the interactive application, is as follows:\n",
    "``` \n",
    "[MET Museum API] -> [Python Data Enrichment (Kaggle Notebook)] -> [Google Cloud Storage]\n",
    "                                                                          |\n",
    "                                                                          v\n",
    "                                                             [BigQuery AI Engine]\n",
    "                                                              /                  \\\n",
    "[ML.GENERATE_EMBEDDING] -> [Vector Table] -> [VECTOR_SEARCH] <---> [Interactive App (UI)] <---> [ML.GENATE_TEXT (Gemini)]\n",
    "``` \n",
    "\n",
    "Upon successful execution of this notebook, all necessary GCP assets will be ready to serve the front-end application.\n",
    "\n",
    "### **3. Next Steps**\n",
    "\n",
    "Once this pipeline has been successfully run, you can proceed to the main application notebook, `ArtExplorer_AI_Docent_(Application).ipynb`, to experience the interactive AI Docent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a448028",
   "metadata": {
    "papermill": {
     "duration": 0.002697,
     "end_time": "2025-09-19T12:46:49.691438",
     "exception": false,
     "start_time": "2025-09-19T12:46:49.688741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **CELL 1: Environment Setup**\n",
    "\n",
    "This cell prepares the Kaggle environment by installing and configuring the necessary Python libraries. It ensures all Google Cloud clients are up-to-date and resolves a known version conflict with the `protobuf` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc885d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T12:46:49.699027Z",
     "iopub.status.busy": "2025-09-19T12:46:49.698594Z",
     "iopub.status.idle": "2025-09-19T12:47:45.036476Z",
     "shell.execute_reply": "2025-09-19T12:47:45.035108Z"
    },
    "papermill": {
     "duration": 55.343931,
     "end_time": "2025-09-19T12:47:45.038461",
     "exception": false,
     "start_time": "2025-09-19T12:46:49.694530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/6] Setting up the environment: Installing and configuring libraries... ---\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.25.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.32.1 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "grpcio-status 1.75.0 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.25.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m✅ Library setup complete.\n",
      "ℹ️ A kernel restart may be recommended for the library changes to take full effect.\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: SETUP - Install and Configure Libraries\n",
    "# ===================================================================\n",
    "print(\"--- [1/6] Setting up the environment: Installing and configuring libraries... ---\")\n",
    "\n",
    "# Upgrade core Google Cloud libraries...\n",
    "!pip install --upgrade -q google-cloud-bigquery google-cloud-storage google-cloud-bigquery-storage google-cloud-aiplatform \n",
    "\n",
    "# Downgrade the protobuf library...\n",
    "!pip install -q protobuf==3.20.3\n",
    "\n",
    "print(\"✅ Library setup complete.\")\n",
    "print(\"ℹ️ A kernel restart may be recommended for the library changes to take full effect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66250324",
   "metadata": {
    "papermill": {
     "duration": 0.003835,
     "end_time": "2025-09-19T12:47:45.046558",
     "exception": false,
     "start_time": "2025-09-19T12:47:45.042723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **CELL 2: Authentication & Global Configuration**\n",
    "\n",
    "This cell is the foundational setup block for the entire notebook. It performs three critical tasks:\n",
    "\n",
    "1.  **Imports Libraries**: All necessary Python libraries for the project are imported here.\n",
    "2.  **GCP Authentication**: It authenticates with GCP using a secure Service Account key stored in Kaggle Secrets.\n",
    "3.  **Global Configuration**: It defines all essential global variables (Project ID, Bucket Name, etc.) in one central location.\n",
    "\n",
    "---\n",
    "> 🔐 **Important Prerequisite: Connecting Kaggle Secrets**\n",
    ">\n",
    "> To run this notebook, you must first have a Kaggle Secret named `GCP_CREDENTIALS` containing your GCP Service Account JSON key.\n",
    ">\n",
    "> **On the first run**, Kaggle will automatically detect that this notebook needs access to the secret and will display a pop-up window asking you to **\"Attach Secret\"**.\n",
    ">\n",
    "> **Please click the \"Attach\" button in the pop-up to proceed.** You may need to run this cell a second time after attaching the secret for the authentication to complete successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a8f75f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T12:47:45.056713Z",
     "iopub.status.busy": "2025-09-19T12:47:45.055918Z",
     "iopub.status.idle": "2025-09-19T12:47:58.731038Z",
     "shell.execute_reply": "2025-09-19T12:47:58.729525Z"
    },
    "papermill": {
     "duration": 13.683176,
     "end_time": "2025-09-19T12:47:58.733676",
     "exception": false,
     "start_time": "2025-09-19T12:47:45.050500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/6] Importing libraries, authenticating, and setting configuration... ---\n",
      "✅ Service Account authentication successful.\n",
      "✅ Configuration loaded for Project ID: semantic-art-explorer\n",
      "✅ BigQuery and GCS clients initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: AUTHENTICATION & GLOBAL CONFIGURATION\n",
    "# ===================================================================\n",
    "print(\"--- [2/6] Importing libraries, authenticating, and setting configuration... ---\")\n",
    "\n",
    "# --- 1. Import All Project Libraries ---\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import service_account\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from tqdm.auto import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# --- 2. GCP Service Account Authentication ---\n",
    "# Disable Kaggle's default GCP integration to prevent any conflicts with our\n",
    "# explicit Service Account authentication method.\n",
    "os.environ['KAGGLE_DISABLE_GCP_INTEGRATION'] = 'true'\n",
    "\n",
    "# Load the service account key from Kaggle Secrets.\n",
    "user_secrets = UserSecretsClient()\n",
    "gcp_key_string = user_secrets.get_secret(\"GCP_CREDENTIALS\")\n",
    "gcp_key_json = json.loads(gcp_key_string)\n",
    "\n",
    "# Define the necessary permission scopes to grant full access to GCP services.\n",
    "scopes = ['https://www.googleapis.com/auth/cloud-platform']\n",
    "\n",
    "# Create the final credentials object using the key and defined scopes.\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    gcp_key_json,\n",
    "    scopes=scopes\n",
    ")\n",
    "print(\"✅ Service Account authentication successful.\")\n",
    "\n",
    "# --- 3. Global Project Configuration ---\n",
    "# All key parameters for the project are defined here.\n",
    "# ❗ Ensure these values match your GCP environment setup.\n",
    "PROJECT_ID = \"semantic-art-explorer\"\n",
    "YOUR_BUCKET_NAME = \"semantic-art-explorer-20250829\"\n",
    "DATASET_ID = \"art_dataset\"  # Using a consistent, clean name.\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "# --- 4. Data Processing Limit (for Development & Testing) ---\n",
    "# Set to an integer (e.g., 100) for quick tests, or None to process the entire dataset.\n",
    "LIMIT_ROWS = None\n",
    "\n",
    "print(f\"✅ Configuration loaded for Project ID: {PROJECT_ID}\")\n",
    "\n",
    "# --- 5. Initialize GCP Clients ---\n",
    "# Instantiate clients for BigQuery and Cloud Storage, passing the explicit\n",
    "# credentials object to ensure stable and correct authentication.\n",
    "bq_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=credentials)\n",
    "print(\"✅ BigQuery and GCS clients initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd3d75",
   "metadata": {
    "papermill": {
     "duration": 0.004666,
     "end_time": "2025-09-19T12:47:58.744212",
     "exception": false,
     "start_time": "2025-09-19T12:47:58.739546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **CELL 3: Data Pipeline - Fetch, Enrich, and Upload to GCS**\n",
    "\n",
    "This cell constitutes the primary data engineering pipeline for the project. It automates the process of acquiring, cleaning, and preparing the artwork data for use in our BigQuery AI models. The pipeline consists of four main stages:\n",
    "\n",
    "1.  **Download**: Fetches the initial `MetObjects.csv` dataset from the official MET Museum source on GitHub.\n",
    "2.  **Filter**: Cleans the raw data, selecting only the artworks that are relevant for our use case (i.e., public domain paintings with descriptive tags).\n",
    "3.  **Enrich**: Iterates through the filtered artworks, calling the MET Collection API for each one to gather richer metadata. This data is then synthesized into a detailed text description (`enriched_text`), which is crucial for generating high-quality text embeddings.\n",
    "4.  **Upload**: Pushes the final, enriched DataFrame to a Google Cloud Storage (GCS) bucket, making it readily available for ingestion into BigQuery in the next step.\n",
    "---\n",
    "> ### **A Note on Data Enrichment Results**\n",
    ">\n",
    "> You will notice that while the initial filtering step identifies a large number of potential artworks (e.g., 2,322), the final enriched dataset contains a smaller number (e.g., 81 artworks in a test run).\n",
    ">\n",
    "> This is an expected and intentional outcome of our robust data enrichment process. The `enrich_artwork_data` function calls the live MET Collection API for each artwork. Some of these API calls may fail due to various real-world factors, such as missing data for a specific Object ID on the API server or transient network issues.\n",
    ">\n",
    "> Our pipeline is designed to be resilient: instead of failing the entire process, it gracefully skips any artwork for which enrichment fails, ensuring that only complete, high-quality data is included in the final dataset. This demonstrates a practical approach to handling real-world, imperfect data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8b701d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T12:47:58.757590Z",
     "iopub.status.busy": "2025-09-19T12:47:58.757025Z",
     "iopub.status.idle": "2025-09-19T12:50:16.007638Z",
     "shell.execute_reply": "2025-09-19T12:50:16.006455Z"
    },
    "papermill": {
     "duration": 137.261303,
     "end_time": "2025-09-19T12:50:16.009916",
     "exception": false,
     "start_time": "2025-09-19T12:47:58.748613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [3/6] Starting the data processing pipeline... ---\n",
      "\n",
      "--- [Step 1/4] Downloading source data from GitHub... ---\n",
      "✅ Download complete. Loaded 484956 total records.\n",
      "\n",
      "--- [Step 2/4] Filtering for public domain paintings... ---\n",
      "✅ Filtering complete. Found 2322 artworks to process.\n",
      "\n",
      "--- [Step 3/4] Enriching 2322 artworks via MET API (this may take a while)... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4c4e4376344ff4860733790ab90f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Enriching artworks:   0%|          | 0/2322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enrichment complete! Successfully processed 83 artworks.\n",
      "\n",
      "--- [Step 4/4] Uploading enriched data to GCS at: gs://semantic-art-explorer-20250829/paintings_enriched_final.csv ---\n",
      "✅ GCS upload complete!\n",
      "\n",
      "--- Data Pipeline Finished ---\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 3: DATA PIPELINE - Fetch, Enrich, and Upload to GCS\n",
    "# ===================================================================\n",
    "print(\"--- [3/6] Starting the data processing pipeline... ---\")\n",
    "\n",
    "# --- 1. Download Source Data ---\n",
    "# Download the MetObjects dataset from the official MET Museum GitHub repository.\n",
    "URL = \"https://media.githubusercontent.com/media/metmuseum/openaccess/master/MetObjects.csv\"\n",
    "print(\"\\n--- [Step 1/4] Downloading source data from GitHub... ---\")\n",
    "df = pd.read_csv(URL, low_memory=False)\n",
    "print(f\"✅ Download complete. Loaded {len(df)} total records.\")\n",
    "\n",
    "# --- 2. Filter for Relevant Artworks ---\n",
    "# Filter the dataset to include only public domain paintings that have associated tags.\n",
    "print(\"\\n--- [Step 2/4] Filtering for public domain paintings... ---\")\n",
    "required_columns = ['Object ID', 'Is Public Domain', 'Department', 'Title', 'Artist Display Name', 'Tags']\n",
    "filtered_df = df.dropna(subset=required_columns).copy()\n",
    "filtered_df = filtered_df[filtered_df['Is Public Domain'] == True]\n",
    "filtered_df = filtered_df[filtered_df['Department'].str.contains('Paintings', na=False)]\n",
    "\n",
    "# Apply the row limit defined in CELL 2 for development and testing.\n",
    "initial_paintings_df = filtered_df if LIMIT_ROWS is None else filtered_df.head(LIMIT_ROWS)\n",
    "print(f\"✅ Filtering complete. Found {len(initial_paintings_df)} artworks to process.\")\n",
    "\n",
    "# --- 3. Enrich Data via MET Collection API ---\n",
    "# For each artwork, call the MET API to get detailed metadata and construct\n",
    "# a rich text description that will be used for generating embeddings.\n",
    "print(f\"\\n--- [Step 3/4] Enriching {len(initial_paintings_df)} artworks via MET API (this may take a while)... ---\")\n",
    "tqdm.pandas(desc=\"Enriching artworks\")\n",
    "\n",
    "def enrich_artwork_data(row):\n",
    "    \"\"\"\n",
    "    Fetches detailed data for a single artwork from the MET API and formats it\n",
    "    into a structured dictionary, including a synthesized 'enriched_text' field.\n",
    "    \"\"\"\n",
    "    object_id = row['Object ID']\n",
    "    try:\n",
    "        api_url = f\"https://collectionapi.metmuseum.org/public/collection/v1/objects/{object_id}\"\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            api_data = response.json()\n",
    "            # Combine key metadata fields into a single, descriptive text string.\n",
    "            enriched_text = (\n",
    "                f\"Title: {api_data.get('title', '')}. \"\n",
    "                f\"Artist: {api_data.get('artistDisplayName', '')}. \"\n",
    "                f\"Type: {api_data.get('objectName', '')}. \"\n",
    "                f\"Medium: {api_data.get('medium', '')}. \"\n",
    "                f\"Date: {api_data.get('objectDate', '')}. \"\n",
    "                f\"Description: {api_data.get('creditLine', '')}. \"\n",
    "                f\"Tags: {row['Tags']}\"\n",
    "            )\n",
    "            return {\n",
    "                'Object_ID': object_id,\n",
    "                'Title': api_data.get('title'),\n",
    "                'Artist_Display_Name': api_data.get('artistDisplayName'),\n",
    "                'Link_Resource': api_data.get('primaryImageSmall') or api_data.get('primaryImage'),\n",
    "                'Tags': row['Tags'],\n",
    "                'enriched_text': enriched_text\n",
    "            }\n",
    "    except requests.exceptions.RequestException:\n",
    "        # Silently ignore network-related errors (e.g., timeouts) for robustness.\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Apply the enrichment function to each row in the DataFrame using progress_apply for a visual progress bar.\n",
    "enriched_results = initial_paintings_df.progress_apply(enrich_artwork_data, axis=1)\n",
    "final_enriched_df = pd.DataFrame(enriched_results.dropna().tolist())\n",
    "print(f\"✅ Enrichment complete! Successfully processed {len(final_enriched_df)} artworks.\")\n",
    "\n",
    "# --- 4. Upload Enriched Data to GCS ---\n",
    "# Upload the final DataFrame as a CSV file to the designated GCS bucket.\n",
    "# This file will serve as the source for our BigQuery table in the next step.\n",
    "gcs_path = f\"gs://{YOUR_BUCKET_NAME}/paintings_enriched_final.csv\"\n",
    "print(f\"\\n--- [Step 4/4] Uploading enriched data to GCS at: {gcs_path} ---\")\n",
    "\n",
    "# Explicitly pass the 'credentials' object to the pandas to_csv function.\n",
    "# This is crucial for authenticating with GCS when using the Service Account method.\n",
    "final_enriched_df.to_csv(\n",
    "    gcs_path,\n",
    "    index=False,\n",
    "    storage_options={'token': credentials}\n",
    ")\n",
    "print(\"✅ GCS upload complete!\")\n",
    "print(\"\\n--- Data Pipeline Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d367d0",
   "metadata": {
    "papermill": {
     "duration": 0.004162,
     "end_time": "2025-09-19T12:50:16.018985",
     "exception": false,
     "start_time": "2025-09-19T12:50:16.014823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **CELL 4: BigQuery Setup - Create Table and AI Models**\n",
    "\n",
    "This cell prepares the core BigQuery infrastructure for our project. It uses the data uploaded to GCS in the previous step to create the necessary tables and AI models within BigQuery. The process includes:\n",
    "\n",
    "1.  **Dataset Creation**: Ensures a BigQuery Dataset exists to act as a container for our tables and models.\n",
    "2.  **Table Ingestion**: Loads the enriched CSV data from Google Cloud Storage into a new BigQuery table named `paintings_enriched`.\n",
    "3.  **Remote Model Creation**: Creates BigQuery ML (BQML) remote models that serve as a bridge to powerful Vertex AI endpoints. This enables us to perform text embedding and text generation directly within BigQuery using simple SQL commands.\n",
    "\n",
    "---\n",
    "> ⚠️ **Prerequisite: BigQuery Connection**\n",
    ">\n",
    "> For this cell to succeed, you must have a **BigQuery Connection for Vertex AI** named **`vertex_ai_connection_us`** created in your GCP project within the `us-central1` region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da04ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T12:50:16.029410Z",
     "iopub.status.busy": "2025-09-19T12:50:16.029076Z",
     "iopub.status.idle": "2025-09-19T12:50:25.048982Z",
     "shell.execute_reply": "2025-09-19T12:50:25.047778Z"
    },
    "papermill": {
     "duration": 9.027135,
     "end_time": "2025-09-19T12:50:25.050552",
     "exception": false,
     "start_time": "2025-09-19T12:50:16.023417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [4/6] Starting BigQuery setup... ---\n",
      "\n",
      "--- [Step 1/3] Ensuring BigQuery dataset 'semantic-art-explorer.art_dataset' exists... ---\n",
      "✅ Dataset 'art_dataset' already exists.\n",
      "\n",
      "--- [Step 2/3] Loading data from GCS into table 'semantic-art-explorer.art_dataset.paintings_enriched'... ---\n",
      "✅ Table created and data loaded successfully.\n",
      "\n",
      "--- [Step 3/3] Creating BQML remote models for Vertex AI... ---\n",
      "✅ Text embedding model ('art_embedding_model') created.\n",
      "✅ Generative model ('art_storytelling_model') created.\n",
      "\n",
      "--- BigQuery Setup Finished ---\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 4: BIGQUERY SETUP - Create Table and AI Models\n",
    "# ===================================================================\n",
    "print(\"--- [4/6] Starting BigQuery setup... ---\")\n",
    "\n",
    "# --- 1. Define BigQuery Resource Names ---\n",
    "# Use the global variables from CELL 2 to define the full names for our BigQuery resources.\n",
    "dataset_id_full = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "table_id = f\"{dataset_id_full}.paintings_enriched\"\n",
    "gcs_path = f\"gs://{YOUR_BUCKET_NAME}/paintings_enriched_final.csv\"\n",
    "connection_id = f\"{PROJECT_ID}.{REGION}.vertex_ai_connection_us\"\n",
    "\n",
    "# --- 2. Create BigQuery Dataset (if it doesn't exist) ---\n",
    "print(f\"\\n--- [Step 1/3] Ensuring BigQuery dataset '{dataset_id_full}' exists... ---\")\n",
    "try:\n",
    "    bq_client.get_dataset(dataset_id_full)\n",
    "    print(f\"✅ Dataset '{DATASET_ID}' already exists.\")\n",
    "except Exception:\n",
    "    print(f\"Dataset '{DATASET_ID}' not found. Creating new dataset in {REGION}...\")\n",
    "    dataset = bigquery.Dataset(dataset_id_full)\n",
    "    dataset.location = REGION\n",
    "    bq_client.create_dataset(dataset, timeout=30)\n",
    "    print(f\"✅ Dataset '{DATASET_ID}' created successfully.\")\n",
    "\n",
    "# --- 3. Load Data from GCS into a BigQuery Table ---\n",
    "print(f\"\\n--- [Step 2/3] Loading data from GCS into table '{table_id}'... ---\")\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True, skip_leading_rows=1,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    write_disposition=\"WRITE_TRUNCATE\"\n",
    ")\n",
    "load_job = bq_client.load_table_from_uri(gcs_path, table_id, job_config=job_config)\n",
    "load_job.result()\n",
    "print(\"✅ Table created and data loaded successfully.\")\n",
    "\n",
    "# --- 4. Create BigQuery ML (BQML) Remote Models ---\n",
    "print(\"\\n--- [Step 3/3] Creating BQML remote models for Vertex AI... ---\")\n",
    "\n",
    "# A. Text Embedding Model\n",
    "# This model will be used to convert text descriptions into numerical vectors.\n",
    "text_model_query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id_full}.art_embedding_model`\n",
    "    REMOTE WITH CONNECTION `{connection_id}`\n",
    "    OPTIONS (endpoint = 'text-embedding-004');\n",
    "\"\"\"\n",
    "bq_client.query(text_model_query).result()\n",
    "print(\"✅ Text embedding model ('art_embedding_model') created.\")\n",
    "\n",
    "# B. Generative (Gemini) Model for Storytelling\n",
    "# This model will be used to generate creative narratives about the artworks.\n",
    "story_model_query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id_full}.art_storytelling_model`\n",
    "    REMOTE WITH CONNECTION `{connection_id}`\n",
    "    OPTIONS (endpoint = 'gemini-2.0-flash-001');\n",
    "\"\"\"\n",
    "bq_client.query(story_model_query).result()\n",
    "print(\"✅ Generative model ('art_storytelling_model') created.\")\n",
    "print(\"\\n--- BigQuery Setup Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224599d0",
   "metadata": {
    "papermill": {
     "duration": 0.004381,
     "end_time": "2025-09-19T12:50:25.059847",
     "exception": false,
     "start_time": "2025-09-19T12:50:25.055466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **CELL 5: Feature Engineering - Generate Text Embeddings**\n",
    "\n",
    "This cell performs the core feature engineering task of the project. It uses the `art_embedding_model` created in the previous step to convert the natural language descriptions (`enriched_text`) for each artwork into high-dimensional numerical vectors, also known as embeddings.\n",
    "\n",
    "The process involves:\n",
    "\n",
    "1.  **Reading** the `paintings_enriched` table.\n",
    "2.  **Applying** the `ML.GENERATE_EMBEDDING` function to the text column.\n",
    "3.  **Storing** the original data along with the newly generated vectors into a new table, `paintings_enriched_with_vectors`.\n",
    "\n",
    "This final table, containing a unique vector for each artwork, is the foundation for enabling powerful semantic search capabilities in the final application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3afef4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T12:50:25.071069Z",
     "iopub.status.busy": "2025-09-19T12:50:25.070258Z",
     "iopub.status.idle": "2025-09-19T12:50:28.170489Z",
     "shell.execute_reply": "2025-09-19T12:50:28.169345Z"
    },
    "papermill": {
     "duration": 3.107595,
     "end_time": "2025-09-19T12:50:28.172155",
     "exception": false,
     "start_time": "2025-09-19T12:50:25.064560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [5/6] Starting Feature Engineering: Generating text embeddings... ---\n",
      "\n",
      "--- [Step 1/1] Generating vectors and creating table 'semantic-art-explorer.art_dataset.paintings_enriched_with_vectors'... ---\n",
      "✅ Final vector table created successfully.\n",
      "\n",
      "--- Feature Engineering Finished: Data is now ready for semantic search! ---\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 5: FEATURE ENGINEERING - Generate Text Embeddings\n",
    "# ===================================================================\n",
    "print(\"--- [5/6] Starting Feature Engineering: Generating text embeddings... ---\")\n",
    "\n",
    "# --- 1. Define Table and Model Names ---\n",
    "# Define the full names for the source table, the target table, and the model\n",
    "# to be used, ensuring clarity and easy maintenance.\n",
    "dataset_id_full = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "source_table_id = f\"{dataset_id_full}.paintings_enriched\"\n",
    "target_table_id = f\"{dataset_id_full}.paintings_enriched_with_vectors\"\n",
    "text_model_id = f\"{dataset_id_full}.art_embedding_model\"\n",
    "\n",
    "# --- 2. Construct and Execute the Embedding Generation Query ---\n",
    "# This SQL query reads the source table, applies the text embedding model to each\n",
    "# row, and saves the output to a new, permanent table.\n",
    "create_vector_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{target_table_id}` AS\n",
    "SELECT\n",
    "    base.*, -- Select all original columns from the source table.\n",
    "    ml_generate_embedding_result AS enriched_text_embedding -- Alias the new vector column for clarity.\n",
    "FROM\n",
    "    ML.GENERATE_EMBEDDING(\n",
    "        MODEL `{text_model_id}`,\n",
    "        -- The ML.GENERATE_EMBEDDING function requires the text input column\n",
    "        -- to be named 'content'. This subquery selects all columns from the\n",
    "        -- source table and creates a temporary alias for our 'enriched_text'\n",
    "        -- column to match this requirement.\n",
    "        (SELECT *, enriched_text AS content FROM `{source_table_id}`)\n",
    "    ) AS base;\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n--- [Step 1/1] Generating vectors and creating table '{target_table_id}'... ---\")\n",
    "\n",
    "# Execute the query and wait for the job to complete. This can take several minutes\n",
    "# depending on the number of rows being processed.\n",
    "bq_client.query(create_vector_table_query).result()\n",
    "print(\"✅ Final vector table created successfully.\")\n",
    "print(\"\\n--- Feature Engineering Finished: Data is now ready for semantic search! ---\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 228.023948,
   "end_time": "2025-09-19T12:50:31.622427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-19T12:46:43.598479",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "15c1da906c03434995950cc52bdaf509": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2d82b50f9bf94340b7c2869e8f28c437": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "439914614463457187ae97fc5c26fe10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc0278f17d9f4755b21b99ddbbb03f2e",
       "max": 2322.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_15c1da906c03434995950cc52bdaf509",
       "tabbable": null,
       "tooltip": null,
       "value": 2322.0
      }
     },
     "64d8af74677e45db82bf66cc909c62c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66be1419828e44b8b1b0b1914bbccb86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc0278f17d9f4755b21b99ddbbb03f2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce4293355e0d42a5af6f09cedcc97213": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d82b50f9bf94340b7c2869e8f28c437",
       "placeholder": "​",
       "style": "IPY_MODEL_f92bb45fe7f749a9bf35ff3f3bb1b15f",
       "tabbable": null,
       "tooltip": null,
       "value": "Enriching artworks: 100%"
      }
     },
     "e146910544254c0cab2ca556ae50a344": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_66be1419828e44b8b1b0b1914bbccb86",
       "placeholder": "​",
       "style": "IPY_MODEL_e32a8a7db97b4bec987aeb1200b9cef8",
       "tabbable": null,
       "tooltip": null,
       "value": " 2322/2322 [02:00&lt;00:00, 21.85it/s]"
      }
     },
     "e32a8a7db97b4bec987aeb1200b9cef8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ea4c4e4376344ff4860733790ab90f6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ce4293355e0d42a5af6f09cedcc97213",
        "IPY_MODEL_439914614463457187ae97fc5c26fe10",
        "IPY_MODEL_e146910544254c0cab2ca556ae50a344"
       ],
       "layout": "IPY_MODEL_64d8af74677e45db82bf66cc909c62c1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f92bb45fe7f749a9bf35ff3f3bb1b15f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
